{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d3d443-38db-4329-a4d9-7c5b0bf7139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://drive.google.com/uc?id=1HWczIICsMpaL8EJyu48ZvRFcXx3_pcnb'\n",
    "data = pd.read_csv(url)\n",
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Downloads\\nlp_dataset.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a8e7ce2-b275-494b-9c46-0ff33d0fbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tools for preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean and preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenization (split the text into words)\n",
    "    words = text.split()\n",
    "    # Remove stopwords and lemmatize each word\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply preprocessing to the 'Comment' column\n",
    "df['Comment'] = df['Comment'].apply(preprocess_text)\n",
    "\n",
    "# Splitting dataset into training and testing sets\n",
    "X = df['Comment']\n",
    "y = df['Emotion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957462d-923f-45e8-8f5b-3fa603bb1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Explanation of Techniques:\n",
    "Text Cleaning: Removes unwanted characters helps to ensure that the text data is consistent and uniform for analysis.\n",
    "Tokenization: Breaks the text into individual words that can be processed by machine learning models.\n",
    "Stopwords Removal: Removes common words helps to focus on the meaningful parts of the text.\n",
    "Lemmatization: Reduces words to their base form, minimizing dimensionality and ensuring that words with similar meanings are treated similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "050afcb2-be6d-4fed-b1a6-694c716d176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initializing TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fitting and transforming the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transforming the test data using the same vectorizer\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af09d5-9dd0-421a-bca2-734982ef07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Extraction Explanation:\n",
    "CountVectorizer takes the text and converts it into a matrix, where each word is represented by how many times it appears in each document. However, it only counts the frequency of words without considering their importance.\n",
    "TfidfVectorizer takes this a step further by assigning a weight to each word. This weight reflects not only how often a word appears in a particular document but also how rare or common it is across all documents. By doing this, it highlights words that are more unique and meaningful for classification, helping the model focus on the most important terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7848b887-d227-483e-a9ae-c30c343831e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.92      0.90       392\n",
      "        fear       0.91      0.91      0.91       416\n",
      "         joy       0.92      0.88      0.90       380\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.91      0.90      0.90      1188\n",
      "weighted avg       0.91      0.90      0.90      1188\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.92      0.96      0.94       392\n",
      "        fear       0.97      0.92      0.94       416\n",
      "         joy       0.94      0.96      0.95       380\n",
      "\n",
      "    accuracy                           0.94      1188\n",
      "   macro avg       0.94      0.95      0.94      1188\n",
      "weighted avg       0.95      0.94      0.94      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel='linear')  # Linear kernel works well for text data\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict with both models\n",
    "nb_predictions = nb_model.predict(X_test_tfidf)\n",
    "svm_predictions = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the models\n",
    "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, nb_predictions))\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ffd59c-5d08-4438-948e-6910552e2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Development Explanation\n",
    "Naive Bayes: This model is straightforward and quick, making it especially useful when dealing with text data that is sparse (where most of the words don’t appear in many documents) and when the words in the text can be treated as independent of each other.\n",
    "SVM: Support Vector Machines work well with complex data, which is common in text. It's particularly good when the data can’t be separated in a simple, straight line but can be split in a higher-dimensional space. This allows it to handle more intricate patterns and make more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed275113-0517-496e-baf2-9a4ea59fbce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
